"""
GitVerified Agent: Integrity (Fraud Trap)
Protocol: TRUST_BUT_VERIFY
Logic: PDF Internal Inspection (White Text / Tiny Font) -> REAL IMPLEMENTATION

Dependency: pymupdf (fitz)
"""

import json
import sys
import fitz  # PyMuPDF
import re

def scan_pdf_integrity(pdf_path):
    print(f"> [Agent:Integrity] Scanning PDF structure: {pdf_path}", file=sys.stderr)
    
    try:
        doc = fitz.open(pdf_path)
    except Exception as e:
        return {
            "agent": "integrity",
            "integrity_score": 0,
            "verdict": "ERROR",
            "flags": [f"CORRUPT FILE: {str(e)}"]
        }
    
    score = 100
    flags = []
    
    total_text = ""
    white_text_found = False
    micro_text_found = False
    keywords_stuffed = False
    
    # 1. METADATA CHECK
    metadata = doc.metadata
    if metadata.get('producer', '').lower().find('canva') != -1:
        flags.append("NOTICE: PDF generated by Canva (Likely Template).")
    
    # 2. LAYER & TEXT ANALYSIS
    for page_num, page in enumerate(doc):
        # Extract text blocks with detail
        # dict = page.get_text("dict")
        # For simple white text check, we look at color if possible, but fitz raw dict is complex.
        # Heuristic: Check for huge text dumps in small areas (OCR/Hidden layers)
        
        text = page.get_text()
        total_text += text
        
        # Check for Micro Text (Heuristic: massive char count per line)
        lines = text.split('\n')
        for line in lines:
            if len(line) > 300: # Suspiciously long line
                micro_text_found = True
    
    # 3. WHITE TEXT / KEYWORD STUFFING (Regex Heuristic)
    # Looking for repeated keywords hidden in patterns
    tech_keywords = ["java", "python", "sql", "react", "aws", "docker"]
    for kw in tech_keywords:
        # If a keyword appears > 50 times, it's stuffing
        if total_text.lower().count(kw) > 50:
            keywords_stuffed = True
            flags.append(f"Keyword Stuffing Detected: '{kw}' count > 50")

    if micro_text_found:
        score -= 30
        flags.append("WARNING: Micro-text/Hidden Layers detected.")
        
    if keywords_stuffed:
        score -= 50
        flags.append("CRITICAL: Keyword Stuffing detected.")
        
    if len(total_text) < 100 and doc.page_count > 0:
        score -= 20
        flags.append("WARNING: Low text content (Image-based PDF?).")

    # Final Verdict
    if score == 100:
        verdict = "CLEAN"
        flags.append("No forensic anomalies detected.")
    elif score > 60:
        verdict = "SUSPICIOUS"
    else:
        verdict = "TAMPERED"
        
    # EXTRACT GITHUB LINKS (Killer Feature)
    github_links = re.findall(r'(https?://github\.com/[a-zA-Z0-9-_]+/[a-zA-Z0-9-_]+)', total_text)
    unique_links = list(set(github_links))

    return {
        "agent": "integrity",
        "integrity_score": score,
        "verdict": verdict,
        "flags": flags,
        "extracted_links": unique_links,
        "metadata": {
            "author": metadata.get('author'),
            "creator": metadata.get('creator'),
            "heatmap_analysis_enabled": True 
        }
    }

def main():
    try:
        if len(sys.argv) < 2:
            print("Usage: python agent_integrity.py <pdf_path>")
            sys.exit(1)
            
        pdf_path = sys.argv[1]
        result = scan_pdf_integrity(pdf_path)
        print(json.dumps(result, indent=2))
        
    except Exception as e:
        print(json.dumps({"error": str(e)}))
        sys.exit(1)

if __name__ == "__main__":
    main()
